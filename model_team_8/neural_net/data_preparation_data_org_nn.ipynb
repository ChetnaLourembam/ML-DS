{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d4cc36",
   "metadata": {},
   "source": [
    "# Data preparation for Neural Network sales forecasting (Kaggle-style)\n",
    "\n",
    "This notebook prepares `data_org.csv` for a neural network model.\n",
    "\n",
    "**Goal (supervised learning):** predict **daily sales per Product Group** (target = `Sales Volume`) using:\n",
    "- calendar features (day of week, month)\n",
    "- special days (`is_holiday`, `KielerWoche`)\n",
    "- weather features (Temperature, etc.)\n",
    "- lag & rolling features per Product Group (leakage-safe)\n",
    "\n",
    "**Kaggle split concept**\n",
    "- **Train**: labels known → fit model\n",
    "- **Validation**: labels known → compare models\n",
    "- **Test**: labels unknown → create features and generate predictions later (this notebook exports test features too)\n",
    "\n",
    "> Important: We do **not** use `daily_total_sales` as a feature because it leaks information from the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de83c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (11164, 17)\n",
      "Columns: ['id', 'Date', 'Product Group', 'Sales Volume', 'Cloud Cover', 'Temperature', 'Wind Speed', 'Weather Code', 'Temperature_H', 'Wind Speed_H', 'Cloud Cover_H', 'Precipitation_H', 'KielerWoche', 'Holiday Name (English)', 'month', 'day_of_week', 'daily_total_sales']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Product Group</th>\n",
       "      <th>Sales Volume</th>\n",
       "      <th>Cloud Cover</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Weather Code</th>\n",
       "      <th>Temperature_H</th>\n",
       "      <th>Wind Speed_H</th>\n",
       "      <th>Cloud Cover_H</th>\n",
       "      <th>Precipitation_H</th>\n",
       "      <th>KielerWoche</th>\n",
       "      <th>Holiday Name (English)</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>daily_total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1307011</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>148.828353</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1269.249107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1307013</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>3</td>\n",
       "      <td>201.198426</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1269.249107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1307014</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>4</td>\n",
       "      <td>65.890169</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1269.249107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1307015</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>5</td>\n",
       "      <td>317.475875</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1269.249107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1307012</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2</td>\n",
       "      <td>535.856285</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1269.249107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        Date  Product Group  Sales Volume  Cloud Cover  Temperature  \\\n",
       "0  1307011  2013-07-01              1    148.828353          6.0      17.8375   \n",
       "1  1307013  2013-07-01              3    201.198426          6.0      17.8375   \n",
       "2  1307014  2013-07-01              4     65.890169          6.0      17.8375   \n",
       "3  1307015  2013-07-01              5    317.475875          6.0      17.8375   \n",
       "4  1307012  2013-07-01              2    535.856285          6.0      17.8375   \n",
       "\n",
       "   Wind Speed  Weather Code  Temperature_H  Wind Speed_H  Cloud Cover_H  \\\n",
       "0        15.0          20.0           15.6           3.5         0.6875   \n",
       "1        15.0          20.0           15.6           3.5         0.6875   \n",
       "2        15.0          20.0           15.6           3.5         0.6875   \n",
       "3        15.0          20.0           15.6           3.5         0.6875   \n",
       "4        15.0          20.0           15.6           3.5         0.6875   \n",
       "\n",
       "   Precipitation_H  KielerWoche Holiday Name (English)  month  day_of_week  \\\n",
       "0              0.3            0                    NaN      7            0   \n",
       "1              0.3            0                    NaN      7            0   \n",
       "2              0.3            0                    NaN      7            0   \n",
       "3              0.3            0                    NaN      7            0   \n",
       "4              0.3            0                    NaN      7            0   \n",
       "\n",
       "   daily_total_sales  \n",
       "0        1269.249107  \n",
       "1        1269.249107  \n",
       "2        1269.249107  \n",
       "3        1269.249107  \n",
       "4        1269.249107  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your data\n",
    "DATA_PATH = \"data_prep/data_org.csv\"   # adjust if your folder differs\n",
    "\n",
    "# Load\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Basic checks\n",
    "print(\"Shape:\", data.shape)\n",
    "print(\"Columns:\", list(data.columns))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b4391",
   "metadata": {},
   "source": [
    "## Build clean features (date parsing, holidays, lags/rolling, temperature imputation)\n",
    "\n",
    "We create the following:\n",
    "- `day_of_week`, `month`, `doy` from `Date`\n",
    "- `is_holiday` from `Holiday Name (English)` (1 if not null)\n",
    "- temperature imputation for dates where Temperature is missing (common in Kaggle test) using **historical day-of-year mean**\n",
    "- lag features (`lag_1`, `lag_7`, `lag_14`) and rolling features (`roll_mean_7`, `roll_mean_28`, `roll_std_28`) per Product Group\n",
    "\n",
    "Lag/rolling features are **leakage-safe** because we compute them using `.shift(1)` before rolling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a27d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared shape: (11164, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Product Group</th>\n",
       "      <th>Sales Volume</th>\n",
       "      <th>Cloud Cover</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Weather Code</th>\n",
       "      <th>Temperature_H</th>\n",
       "      <th>Wind Speed_H</th>\n",
       "      <th>...</th>\n",
       "      <th>daily_total_sales</th>\n",
       "      <th>doy</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temp_anomaly</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_14</th>\n",
       "      <th>roll_mean_7</th>\n",
       "      <th>roll_mean_28</th>\n",
       "      <th>roll_std_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1307011</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>148.828353</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1269.249107</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.282143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1307021</td>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>1</td>\n",
       "      <td>159.793757</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.3125</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1430.008397</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>148.828353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1307031</td>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>111.885594</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>6.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1124.274894</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1.026786</td>\n",
       "      <td>159.793757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1307041</td>\n",
       "      <td>2013-07-04</td>\n",
       "      <td>1</td>\n",
       "      <td>168.864941</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.8500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1184.309567</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.995833</td>\n",
       "      <td>111.885594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.169235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1307051</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>1</td>\n",
       "      <td>171.280754</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.9750</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1288.023060</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>168.864941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.343161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       Date  Product Group  Sales Volume  Cloud Cover  Temperature  \\\n",
       "0  1307011 2013-07-01              1    148.828353          6.0      17.8375   \n",
       "1  1307021 2013-07-02              1    159.793757          3.0      17.3125   \n",
       "2  1307031 2013-07-03              1    111.885594          7.0      21.0750   \n",
       "3  1307041 2013-07-04              1    168.864941          7.0      18.8500   \n",
       "4  1307051 2013-07-05              1    171.280754          5.0      19.9750   \n",
       "\n",
       "   Wind Speed  Weather Code  Temperature_H  Wind Speed_H  ...  \\\n",
       "0        15.0          20.0           15.6           3.5  ...   \n",
       "1        10.0           NaN           15.1           2.7  ...   \n",
       "2         6.0          61.0           18.0           2.3  ...   \n",
       "3         7.0          20.0           17.2           2.2  ...   \n",
       "4        12.0           NaN           16.9           3.7  ...   \n",
       "\n",
       "   daily_total_sales  doy  is_holiday temp_anomaly       lag_1  lag_7  lag_14  \\\n",
       "0        1269.249107  182           0    -1.282143    0.000000    0.0     0.0   \n",
       "1        1430.008397  183           0    -2.100000  148.828353    0.0     0.0   \n",
       "2        1124.274894  184           0     1.026786  159.793757    0.0     0.0   \n",
       "3        1184.309567  185           0    -1.995833  111.885594    0.0     0.0   \n",
       "4        1288.023060  186           0     0.075000  168.864941    0.0     0.0   \n",
       "\n",
       "   roll_mean_7  roll_mean_28  roll_std_28  \n",
       "0     0.000000           0.0          0.0  \n",
       "1     0.000000           0.0          0.0  \n",
       "2     0.000000           0.0          0.0  \n",
       "3   140.169235           0.0          0.0  \n",
       "4   147.343161           0.0          0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Parse date and create calendar features ---\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "\n",
    "data[\"day_of_week\"] = data[\"Date\"].dt.dayofweek   # 0=Mon ... 6=Sun\n",
    "data[\"month\"] = data[\"Date\"].dt.month\n",
    "data[\"doy\"] = data[\"Date\"].dt.dayofyear\n",
    "\n",
    "# --- Holiday flag ---\n",
    "holiday_col = \"Holiday Name (English)\" if \"Holiday Name (English)\" in data.columns else None\n",
    "if holiday_col:\n",
    "    data[\"is_holiday\"] = data[holiday_col].notna().astype(int)\n",
    "else:\n",
    "    data[\"is_holiday\"] = 0\n",
    "\n",
    "# KielerWoche should already exist; if not, create a default 0\n",
    "if \"KielerWoche\" not in data.columns:\n",
    "    data[\"KielerWoche\"] = 0\n",
    "\n",
    "# --- Temperature handling ---\n",
    "# Kaggle reality: TEST often has no Temperature. We will impute Temperature using historical day-of-year mean.\n",
    "\n",
    "if \"Temperature\" not in data.columns:\n",
    "    data[\"Temperature\"] = np.nan\n",
    "\n",
    "data[\"Temperature\"] = pd.to_numeric(data[\"Temperature\"], errors=\"coerce\")\n",
    "\n",
    "# Compute DOY mean temperature using only rows where Temperature is known\n",
    "doy_mean_temp = (\n",
    "    data.loc[data[\"Temperature\"].notna()]\n",
    "        .groupby(\"doy\")[\"Temperature\"]\n",
    "        .mean()\n",
    ")\n",
    "\n",
    "# Fill missing temps from DOY mean, then fallback to overall mean\n",
    "data[\"Temperature\"] = data[\"Temperature\"].fillna(data[\"doy\"].map(doy_mean_temp))\n",
    "data[\"Temperature\"] = data[\"Temperature\"].fillna(data[\"Temperature\"].mean())\n",
    "\n",
    "# (Optional) Temperature anomaly: useful if you want to separate seasonal vs unexpected temperature effects\n",
    "data[\"temp_anomaly\"] = data[\"Temperature\"] - data[\"doy\"].map(doy_mean_temp)\n",
    "data[\"temp_anomaly\"] = data[\"temp_anomaly\"].fillna(0.0)\n",
    "\n",
    "# --- Build lag/rolling features per Product Group ---\n",
    "# Target column\n",
    "TARGET_COL = \"Sales Volume\"\n",
    "\n",
    "# Ensure numeric\n",
    "data[TARGET_COL] = pd.to_numeric(data[TARGET_COL], errors=\"coerce\")\n",
    "\n",
    "# Sort for time-series feature engineering\n",
    "data = data.sort_values([\"Product Group\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "g = data.groupby(\"Product Group\")[TARGET_COL]\n",
    "\n",
    "data[\"lag_1\"] = g.shift(1)\n",
    "data[\"lag_7\"] = g.shift(7)\n",
    "data[\"lag_14\"] = g.shift(14)\n",
    "\n",
    "data[\"roll_mean_7\"] = g.shift(1).rolling(window=7, min_periods=3).mean()\n",
    "data[\"roll_mean_28\"] = g.shift(1).rolling(window=28, min_periods=7).mean()\n",
    "data[\"roll_std_28\"] = g.shift(1).rolling(window=28, min_periods=7).std()\n",
    "\n",
    "# Fill NaNs in lag/rolling features (early history) with 0 for modeling convenience\n",
    "for c in [\"lag_1\",\"lag_7\",\"lag_14\",\"roll_mean_7\",\"roll_mean_28\",\"roll_std_28\"]:\n",
    "    data[c] = data[c].fillna(0.0)\n",
    "\n",
    "print(\"Prepared shape:\", data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305836b1",
   "metadata": {},
   "source": [
    "## Time-based Train / Validation / Test split\n",
    "\n",
    "We keep your established split:\n",
    "- Train: 2013-07-01 → 2017-07-31  \n",
    "- Validation: 2017-08-01 → 2018-07-31  \n",
    "- Test: 2018-08-01 → 2019-07-31\n",
    "\n",
    "This respects time order and avoids leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87f10c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2013-07-01 00:00:00 → 2017-07-31 00:00:00 (7493, 26)\n",
      "Val:   2017-08-01 00:00:00 → 2018-07-31 00:00:00 (1841, 26)\n",
      "Test:  2018-08-01 00:00:00 → 2019-07-30 00:00:00 (1830, 26)\n",
      "Test target missing %: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Time splits\n",
    "TRAIN_START, TRAIN_END = \"2013-07-01\", \"2017-07-31\"\n",
    "VAL_START, VAL_END     = \"2017-08-01\", \"2018-07-31\"\n",
    "TEST_START, TEST_END   = \"2018-08-01\", \"2019-07-31\"\n",
    "\n",
    "train = data[(data[\"Date\"] >= TRAIN_START) & (data[\"Date\"] <= TRAIN_END)].copy()\n",
    "val   = data[(data[\"Date\"] >= VAL_START)   & (data[\"Date\"] <= VAL_END)].copy()\n",
    "test  = data[(data[\"Date\"] >= TEST_START)  & (data[\"Date\"] <= TEST_END)].copy()\n",
    "\n",
    "print(\"Train:\", train[\"Date\"].min(), \"→\", train[\"Date\"].max(), train.shape)\n",
    "print(\"Val:  \", val[\"Date\"].min(), \"→\", val[\"Date\"].max(), val.shape)\n",
    "print(\"Test: \", test[\"Date\"].min(), \"→\", test[\"Date\"].max(), test.shape)\n",
    "\n",
    "# Kaggle test often has missing target labels (Sales Volume). That's fine.\n",
    "print(\"Test target missing %:\", test[TARGET_COL].isna().mean() * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36928791",
   "metadata": {},
   "source": [
    "## Encode features for neural networks (one-hot categoricals, scale numeric)\n",
    "\n",
    "We build:\n",
    "- `X_train`, `y_train`\n",
    "- `X_val`, `y_val`\n",
    "- `X_test` (no labels needed)\n",
    "\n",
    "**Categorical columns** are one-hot encoded.\n",
    "**Numeric columns** are standardized (mean 0, std 1) using TRAIN statistics only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c969e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (7493, 46) y_train: (7493,)\n",
      "X_val:   (1841, 46) y_val:   (1841,)\n",
      "X_test:  (1830, 46)\n",
      "Num features: 46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'Cloud Cover',\n",
       " 'Temperature',\n",
       " 'Wind Speed',\n",
       " 'Weather Code',\n",
       " 'Temperature_H',\n",
       " 'Wind Speed_H',\n",
       " 'Cloud Cover_H',\n",
       " 'Precipitation_H',\n",
       " 'doy',\n",
       " 'temp_anomaly',\n",
       " 'lag_1',\n",
       " 'lag_7',\n",
       " 'lag_14',\n",
       " 'roll_mean_7',\n",
       " 'roll_mean_28',\n",
       " 'roll_std_28',\n",
       " 'Product Group_1',\n",
       " 'Product Group_2',\n",
       " 'Product Group_3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Columns to exclude from features (leakage or identifiers)\n",
    "exclude_cols = {\n",
    "    TARGET_COL,          # target\n",
    "    \"Date\",              # keep for indexing, not modeling\n",
    "    \"daily_total_sales\", # leakage: sum of all product sales\n",
    "    \"Holiday Name (English)\",  # text label (we already created is_holiday)\n",
    "}\n",
    "\n",
    "# Categorical columns (you can add/remove here)\n",
    "categorical_cols = [\"Product Group\", \"day_of_week\", \"month\", \"is_holiday\", \"KielerWoche\"]\n",
    "\n",
    "# If you want to let NN learn different weather sensitivity by product group, keep Product Group categorical.\n",
    "# Note: day_of_week/month could also be encoded cyclically (sin/cos), but one-hot is a good baseline.\n",
    "\n",
    "# Select feature columns automatically:\n",
    "feature_cols = [c for c in data.columns if c not in exclude_cols]\n",
    "\n",
    "# Make sure categorical columns exist (if dataset changes)\n",
    "categorical_cols = [c for c in categorical_cols if c in feature_cols]\n",
    "\n",
    "# Split X/y\n",
    "def split_xy(df):\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[TARGET_COL].copy() if TARGET_COL in df.columns else None\n",
    "    return X, y\n",
    "\n",
    "X_train_raw, y_train = split_xy(train)\n",
    "X_val_raw, y_val     = split_xy(val)\n",
    "X_test_raw, _        = split_xy(test)\n",
    "\n",
    "# One-hot encode categoricals (fit on combined to ensure consistent columns)\n",
    "combined = pd.concat([X_train_raw, X_val_raw, X_test_raw], axis=0, ignore_index=True)\n",
    "combined = pd.get_dummies(combined, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "# Re-split after encoding\n",
    "n_tr = len(X_train_raw)\n",
    "n_va = len(X_val_raw)\n",
    "\n",
    "X_train_enc = combined.iloc[:n_tr].copy()\n",
    "X_val_enc   = combined.iloc[n_tr:n_tr+n_va].copy()\n",
    "X_test_enc  = combined.iloc[n_tr+n_va:].copy()\n",
    "\n",
    "# Identify numeric columns to scale\n",
    "numeric_cols = [c for c in X_train_enc.columns if X_train_enc[c].dtype != \"uint8\" and X_train_enc[c].dtype != \"bool\"]\n",
    "\n",
    "# Scale numeric columns using TRAIN stats only\n",
    "scaler = StandardScaler()\n",
    "X_train_enc[numeric_cols] = scaler.fit_transform(X_train_enc[numeric_cols])\n",
    "X_val_enc[numeric_cols]   = scaler.transform(X_val_enc[numeric_cols])\n",
    "X_test_enc[numeric_cols]  = scaler.transform(X_test_enc[numeric_cols])\n",
    "\n",
    "# Final outputs (numpy arrays are NN-friendly)\n",
    "X_train = X_train_enc.to_numpy(dtype=np.float32)\n",
    "X_val   = X_val_enc.to_numpy(dtype=np.float32)\n",
    "X_test  = X_test_enc.to_numpy(dtype=np.float32)\n",
    "\n",
    "y_train = y_train.to_numpy(dtype=np.float32)\n",
    "y_val   = y_val.to_numpy(dtype=np.float32)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape, \"y_val:  \", y_val.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "\n",
    "# Keep feature names for later model interpretation/debugging\n",
    "feature_names = list(X_train_enc.columns)\n",
    "print(\"Num features:\", len(feature_names))\n",
    "feature_names[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export prepared arrays for your Neural Network notebook\n",
    "\n",
    "We export:\n",
    "- `X_train`, `y_train`\n",
    "- `X_val`, `y_val`\n",
    "- `X_test`\n",
    "- `feature_names`\n",
    "- fitted `scaler` (so you can apply the same transform later if needed)\n",
    "- `test_ids` (so predictions can be mapped back to Kaggle submission)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: pickle_data\\nn_data.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "subdirectory = \"pickle_data\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# IDs for Kaggle submission\n",
    "test_ids = test[\"id\"].copy() if \"id\" in test.columns else (\n",
    "    test[\"Date\"].dt.strftime(\"%y%m%d\") + test[\"Product Group\"].astype(str)\n",
    ")\n",
    "\n",
    "with open(os.path.join(subdirectory, \"nn_data.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"X_train\": X_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"X_val\": X_val,\n",
    "            \"y_val\": y_val,\n",
    "            \"X_test\": X_test,\n",
    "            \"test_ids\": test_ids.to_numpy(),\n",
    "            \"feature_names\": feature_names,\n",
    "            \"scaler\": scaler,\n",
    "        },\n",
    "        f,\n",
    "        protocol=pickle.HIGHEST_PROTOCOL,\n",
    "    )\n",
    "\n",
    "print(\"Saved:\", os.path.join(subdirectory, \"nn_data.pkl\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
